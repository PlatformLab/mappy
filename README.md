# *mappy*

*mappy* is an implementation of the Hadoop MapReduce scheduler that shows what
an equivalent job scheduler would look like if a rules-based approach were
applied. *mappy* reimplements functionality provided by 3 classes in the Hadoop
Java implementation:


- [JobImpl.java](reference/JobImpl.java#L239)
- [TaskImpl.java](reference/TaskImpl.java#L147)
- [TaskAttemptImpl.java](reference/TaskAttemptImpl.java#L209)

More specifically, *mappy* reimplements the functionality provided by the 3
state machines found in JobImpl.java, TaskImpl.java, and TaskAttemptImpl.java
as 3 rules engines in [job.py](job.py):

- [Job](job.py#L24)
- [Task](job.py#L131)
- [TaskAttempt](job.py#L215)

The Hadoop event-driven state machines, not surprisingly, relies heavily on
events. For parity, the *mappy* implementation uses the same event names for
events used to interact with modules outside the 3 classes being reimplemented.
Events that Hadoop used to communicate between the 3 classes were eliminated
with equivalent functionality implemented in a more rules-based style.

Although *mappy*'s equivalency the original Hadoop implementation was primarily
verified by hand, as a sanity check we also built a mock MapReduce
implementation around [job.py](job.py) to run the scheduler. The mock
implementation provides the following:

- A "worker" that mocks the behavior of a Hadoop container and simply accepts
  "work" and responds asynchronously after waiting for certain about of time.
- Mock RMContainerAllocator and CommitterEventHandler modules which, like their
  Hadoop counterparts, handle the events generated by the scheduler.
- A basic RPC system for communication.
- A "master" that runs the scheduler and other modules as a Hadoop MapReduce
  master would.

## Running *mappy*

*mappy* can be run by starting a [*master*](master.py) and any number of
[*workers*](worker.py); they can be all run on the same machine or separately a
cluster of machines. The example commands will use a single machine.

By default, modules run in the foreground and print both RPC traffic and
certain events to standard out. As such, each module should be run in separate
command-line terminals. To kill the process, enter Ctrl-C.

To start a master run the [master.py](master.py) module with the following
command which specifies its IP address, PORT number, and number of tasks the
Job should have:

```
./master.py 127.0.0.1 8000 -t 3
```

To start a worker run the [worker.py](worker.py) module with the following
command which specifies its IP address and PORT number as well as the master's
IP address and PORT number:

```
./worker.py 127.0.0.1 8001 127.0.0.1 8000
```

The master will run the scheduler until the Job's goal is reached, all tasks
are run and "committed". If any worker dies (is killed using Ctrl-C) while the
job is running, the scheduler will reschedule the now lost tasks. Once the job
is complete, the master will print the list of tasks and the corresponding
worker that completed the task.

```
Job Complete
<0: SUCCEEDED (u'127.0.0.1', 8001, 3721)>
<1: SUCCEEDED (u'127.0.0.1', 8001, 3721)>
<2: SUCCEEDED (u'127.0.0.1', 8001, 3721)>
```
